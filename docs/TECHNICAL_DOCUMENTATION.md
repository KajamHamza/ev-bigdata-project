# üìã Technical Documentation - EV Big Data Project

## üéØ Project Specifications Compliance

This project fully implements the Big Data module requirements:

### ‚úÖ Required Technologies
- **Apache Kafka**: ‚úì Real-time data ingestion and streaming
- **Elasticsearch + Kibana (ELK stack)**: ‚úì Data processing, indexing, and visualization

### ‚úÖ Project Steps Implementation

#### 1. Real-time Data Source Selection
**Chosen Source**: IoT Sensors (Electric Vehicle Telemetry)
- **Justification**: EV data provides rich, multi-dimensional telemetry perfect for real-time analytics
- **Data Types**: GPS coordinates, battery metrics, speed, energy consumption, diagnostics
- **Frequency**: Configurable (default: 1 second intervals)
- **Volume**: 5 vehicles √ó 1 Hz = 5 messages/second (scalable to hundreds of vehicles)

#### 2. Kafka Data Ingestion
**Implementation**: `kafka-producer/kafka_producer.py`
- **Producer Configuration**: Optimized for reliability with `acks='all'`
- **Topic Strategy**: 
  - `ev-telemetry`: Raw vehicle data
  - `ev-processed`: Enriched data after stream processing
- **Partitioning**: Vehicle ID as key for consistent routing
- **Serialization**: JSON format for flexibility

#### 3. Stream Processing
**Implementation**: `kafka-streams/ev_data_processor.py`
- **Processing Type**: Kafka Streams using Python kafka-python library
- **Enrichment Features**:
  - Statistical calculations (averages, trends, variance)
  - Anomaly detection (battery low, overheating, rapid drain)
  - Derived metrics (efficiency, health scores, driving behavior)
  - Data quality assessment
- **State Management**: In-memory vehicle history (last 10 data points per vehicle)

#### 4. Elasticsearch Integration
**Implementation**: Kafka Connect Elasticsearch Sink
- **Configuration**: `elasticsearch-config/kafka-connect-elasticsearch.json`
- **Index Mapping**: `elasticsearch-config/ev_index_mapping.json`
- **Features**:
  - Optimized field types for time-series data
  - Geo-point mapping for location visualization
  - Nested objects for complex data structures

#### 5. Kibana Visualization
**Implementation**: `kibana-dashboards/ev-dashboard-config.json`
- **Dashboard Components**:
  - Real-time fleet location map
  - Speed and battery timelines
  - Energy consumption analytics
  - Anomaly detection alerts
  - Fleet performance metrics

## üèóÔ∏è Architecture Deep Dive

### Data Flow Architecture

```
EV Simulator ‚Üí Kafka Producer ‚Üí Kafka Topic (ev-telemetry) ‚Üí Kafka Streams Processor
                                                                        ‚Üì
Kibana ‚Üê Elasticsearch ‚Üê Kafka Connect ‚Üê Kafka Topic (ev-processed) ‚Üê‚îÄ‚îÄ‚îò
```

### Component Details

#### 1. EV Data Simulator (`ev_data_simulator.py`)
**Purpose**: Generate realistic electric vehicle telemetry data

**Key Features**:
- **Realistic Physics**: Battery consumption based on speed and usage patterns
- **Driving Patterns**: City driving, highway, parking, charging, idle states
- **GPS Simulation**: Movement around Paris area with realistic coordinate changes
- **Environmental Factors**: Temperature, humidity, air quality affecting performance
- **Vehicle Specifications**: 75kWh battery, 180 km/h max speed, 0.2 kWh/km efficiency

**Data Structure**:
```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "vehicle_id": "uuid",
  "location": {"latitude": 48.8566, "longitude": 2.3522, "altitude": 100},
  "motion": {"speed": 45.2, "acceleration": 1.2, "heading": 180},
  "battery": {"level": 75.5, "voltage": 380, "current": -25, "temperature": 28.5},
  "energy": {"consumption": 0.15, "regeneration": 0.02, "efficiency": 0.2},
  "vehicle_status": {"driving_pattern": "city_driving", "odometer": 15420.5},
  "diagnostics": {"alerts": ["LOW_BATTERY"], "maintenance_due": false},
  "environmental": {"outside_temp": 22.5, "humidity": 65, "air_quality_index": 85}
}
```

#### 2. Kafka Producer (`kafka_producer.py`)
**Purpose**: Stream EV data to Kafka topics

**Configuration**:
- **Reliability**: `acks='all'` ensures all replicas acknowledge
- **Performance**: Batching and compression for throughput
- **Partitioning**: Vehicle ID as key for ordered processing per vehicle
- **Error Handling**: Retry logic and delivery callbacks

**Scalability Features**:
- Configurable number of vehicles (1-1000+)
- Adjustable data frequency (0.1-60 seconds)
- Batch and continuous modes

#### 3. Kafka Streams Processor (`ev_data_processor.py`)
**Purpose**: Real-time data enrichment and anomaly detection

**Processing Logic**:
1. **Statistical Analysis**:
   - Running averages for speed, battery level, consumption
   - Trend detection (increasing/decreasing patterns)
   - Variance calculations for behavior analysis

2. **Anomaly Detection**:
   - **Critical Battery Low**: < 5% charge
   - **Battery Overheating**: > 50¬∞C
   - **Rapid Battery Drain**: > 10% loss in 3 readings
   - **High Speed**: > 150 km/h

3. **Derived Metrics**:
   - Energy efficiency (kWh/100km)
   - Battery health score (0-100)
   - Driving behavior classification
   - Data quality assessment

**State Management**:
- In-memory vehicle history (configurable window size)
- Stateful processing for trend analysis
- Graceful handling of new vehicles

#### 4. Elasticsearch Configuration
**Index Strategy**:
- **Time-based indices**: `ev-processed-YYYY.MM.DD` pattern
- **Optimized mappings**: Proper field types for analytics
- **Geo-point fields**: For location-based queries and visualization

**Performance Optimizations**:
- Single shard for development (scalable to multiple)
- 1-second refresh interval for near real-time
- Compression and field optimization

#### 5. Kibana Dashboards
**Visualization Types**:
- **Map Visualization**: Fleet locations with battery/speed indicators
- **Time Series**: Speed, battery, consumption trends
- **Gauges**: Current battery levels and health scores
- **Pie Charts**: Driving pattern distribution
- **Tables**: Latest vehicle data and alerts

**Real-time Features**:
- 5-second auto-refresh
- Time range filtering (last 15 minutes default)
- Interactive filtering and drill-down

## üîß Technical Implementation Details

### Docker Infrastructure
**Services**:
- **Zookeeper**: Kafka coordination
- **Kafka**: Message streaming (3 partitions per topic)
- **Kafka Connect**: Elasticsearch integration
- **Elasticsearch**: Data storage and indexing
- **Kibana**: Visualization interface
- **Kafka UI**: Monitoring and management

**Resource Allocation**:
- Elasticsearch: 512MB heap
- Total memory requirement: ~4GB
- Network: Bridge network for inter-service communication

### Data Processing Pipeline

#### Ingestion Layer
- **Throughput**: 5-1000+ messages/second (configurable)
- **Latency**: < 100ms producer to Kafka
- **Reliability**: At-least-once delivery guarantee

#### Processing Layer
- **Latency**: < 500ms Kafka to enriched output
- **Throughput**: Matches ingestion rate
- **Fault Tolerance**: Consumer group rebalancing

#### Storage Layer
- **Indexing**: < 1 second from Kafka to Elasticsearch
- **Query Performance**: < 100ms for dashboard queries
- **Retention**: Configurable (default: unlimited)

#### Visualization Layer
- **Refresh Rate**: 5-second dashboard updates
- **Responsiveness**: < 2 seconds for complex visualizations
- **Concurrency**: Multiple users supported

### Scalability Considerations

#### Horizontal Scaling
- **Kafka**: Add brokers and increase partitions
- **Elasticsearch**: Add nodes and shards
- **Processing**: Multiple consumer instances

#### Vertical Scaling
- **Memory**: Increase heap sizes for better performance
- **CPU**: More cores for parallel processing
- **Storage**: SSD for better I/O performance

### Monitoring and Observability

#### Metrics Collection
- **Kafka**: Message rates, consumer lag, partition distribution
- **Elasticsearch**: Index size, query performance, cluster health
- **Application**: Processing rates, error counts, latency

#### Alerting
- **System Health**: Service availability, resource usage
- **Data Quality**: Missing data, processing delays
- **Business Logic**: Critical vehicle alerts, anomaly rates

## üéì Educational Outcomes

### Big Data Concepts Demonstrated

#### 1. Volume
- Continuous data streams from multiple sources
- Scalable to thousands of vehicles
- Historical data accumulation

#### 2. Velocity
- Real-time data ingestion (1-second intervals)
- Stream processing with minimal latency
- Near real-time visualization updates

#### 3. Variety
- Structured telemetry data
- Time-series patterns
- Geospatial information
- Categorical and numerical data types

#### 4. Veracity
- Data quality assessment
- Anomaly detection
- Accuracy validation

### Technical Skills Applied

#### Stream Processing
- Event-driven architecture
- Stateful stream processing
- Real-time analytics

#### Data Engineering
- ETL pipeline design
- Schema evolution
- Data quality management

#### Visualization
- Real-time dashboards
- Geospatial visualization
- Time-series analysis

#### DevOps
- Containerization
- Service orchestration
- Infrastructure as code

## üöÄ Future Enhancements

### Technical Improvements
1. **Machine Learning Integration**: Predictive maintenance, route optimization
2. **Advanced Analytics**: Complex event processing, pattern recognition
3. **Performance Optimization**: Caching, indexing strategies
4. **Security**: Authentication, encryption, access control

### Business Features
1. **Fleet Management**: Vehicle assignment, maintenance scheduling
2. **Energy Optimization**: Charging station recommendations, route planning
3. **Predictive Analytics**: Failure prediction, usage forecasting
4. **Integration**: External APIs, third-party services

### Scalability Enhancements
1. **Cloud Deployment**: Kubernetes, managed services
2. **Multi-Region**: Data replication, disaster recovery
3. **Auto-Scaling**: Dynamic resource allocation
4. **Cost Optimization**: Resource usage monitoring, optimization

---

This technical documentation demonstrates a comprehensive understanding of Big Data technologies and their practical application in a real-world scenario. The project successfully implements all required components while providing educational value and practical insights into modern data engineering practices. 